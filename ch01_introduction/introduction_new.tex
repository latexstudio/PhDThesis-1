%!TEX root = ../thesis.tex

\chapter{Introduction}
\label{chap:intro}

\TODO{Connecting sentences across sections are missing}

\Gls{it} is constantly shaping the world that we live in. The advancements in \gls{it} has changed the patterns of human behavior and influenced the way we connect with our environment. Music being a universal socio-cultural phenomena has been deeply influenced by these advancements. The way music is created, stored, disseminated, listened to, and even learnt has changed drastically over the last few decades. A massive amount of audio music content is now available on demand. Thus, it becomes necessary to develop computational techniques that can process and automatically describe large volumes of digital music content to facilitate novel ways of interaction with music content\TODO{rephrase?}. There are different information sources such as editorial metadata, social data, and audio recordings that can be exploited to generate a description of music.
Melody, along with harmony and rhythm, is a fundamental facet of music, and therefore, an essential component in its description. In this thesis we focus on describing melodic aspects of music through an automated analysis of audio music content. 

\section{Motivation}
\label{sec:motivation}
As put by (Selfridge-Field, 1998). 
It is melody that enables us to distinguish one work from another. It is melody that human beings are innately able to reproduce by singing, humming, and whistling. It is melody that makes music memorable: we are likely to recall a tune long after we have forgotten its text. 

The importance of melody in our musical experiences makes its analysis and description a crucial component in music content processing. It becomes even more important for melody dominant music traditions such as IAM, where the concept of harmony from a music point of view does not exist, and the complex melodic structure takes the central role in music aesthetics.

Melodic analysis and description is not a recent phenomenon, it has been manually done by musicologists for hundreds of years (REF). However, a computational approach to this task has opened up new directions and possibilities, taking it to a different magnitude altogether. Through computational approaches melodic analysis and description can be performed at the level of an entire music repertoire, as opposed to a few music pieces typically considered in manually performed musicological studies. Needless to say that such computational analysis is a work in progress with continuous attempts to improve the quality of the outcomes, so that they closely resemble to what can be done by human experts.

Most of the current computational approaches that analyze higher-level melodic aspects of music work with its symbolic representations, thus covering only a particular view of music. There are significant challenges in extending such approaches to analyze recorded performances, mainly due to the difficulties involved in obtaining a meaningful symbolic representation from audio recordings. Therefore, for performance oriented music traditions such as IAM, where symbolic music representations are practically nonexistent, and the aesthetics lie in the improvisatory aspects, such approaches are not directly applicable. Besides, melody, being a cultural phenomenon, should be studied within the cultural context of a music tradition. Thus, there is a need to develop culture-aware computational approaches that exploit the specificities of a music tradition to analyse and describe the melodic aspects of recorded music performances. Indian art music with its complex melodic framework, \gls{raga}, and well grounded-music theory provides an ideal context to develop such approaches.

Melodic elements in IAM are hierarchically organized in accordance with the raga grammar. At the lowest level there are \glspl{svara}, which concatenate to form melodic phrases. These phrases group together to form passages, finally leading to a music piece. In this thesis we focus on computational approaches that analyse these melodic elements at different hierarchical levels to describe melodic aspects of IAM corpora. 
%Furthermore, through a corpora level analysis across recordings we can develop novel strategies to characterize compositions, artists and ragas, thus gaining useful musical insights. 

\TODO{REPHRASE THIS PARA}
Higher-level (By this we mean description of higher level melodic concepts, which is beyond representing them by predominant pitch.) melodic analysis and description has manifold applications. Such an analysis can enable corpora level musicological studies such as characterization of different compositions, artists and ragas in audio music collections. Since IAM follows an oral pedagogy, analysis of the recorded performances can shed lights on the stylistic influences of a teachers on their students, and across artists. Analyzing and relating different melodic elements in a music collection opens up ways to define novel music similarity measures, and generate semantically meaningful description of higher level musical concepts such as ragas. This further enables several applications such as structuring and organizing of large music collections, raga-based music retrieval and musically relevant music navigation and discovery. A rich description of differnet melodic elements also aids in novel applications addressing enhanced or augmented music listening experience. This aspect specifically relevant in IAM where the music is said to be accessible mainly to musicians and  connoisseurs owing to the complexity of the melodic structures. Besides this, able to analyse and characterize different melodic elements directly from audio recordings opens up novel and creative ways to approach music pedagogy. Specially in the context of IAM where the nuances of the music are learned implicitly through years of training, where analytical and objective description of music performances is largely nonexistent, an objective melodic description can aid music students to learn from the recorded performances of Mastros. 


\section{Scientific Context and Relevance}
\label{sec:context}

\Gls{mir} is a growing interdisciplinary research field that stands at the intersection of well established disciplines such as signal processing, pattern recognition, musicology, psychoacoustics, music perception and cognition, information science, and computer science (machine-learning). \Gls{mir} primarily addresses topics involved in the understanding and modeling of music using information processing methodologies~\citep{roadmap_mir}. In particular, it aims to advance our knowledge in representing, understanding, describing, retrieving, archiving and organizing music related data. This opens up a wealth of possibilities to develop novel ways to interact with music~\citep{casey2008content,orio2006music,burgoyne2016music}.  

The field of \gls{mir} has made significant advancements in the last two decades. Its growth is fueled by the massive surge in the digital music content. MIR systems aim to describe and characterize music content in terms of different musical facets such as melody, rhythm, harmony, structure and emotion. The definition, interpretation and relevance of these musical aspects are not universal and vary significantly across different music traditions, and personal, cultural and social contexts. A significant number of existing computational approaches in \gls{mir} fail to account for these factors, and thus, might be hitting the so-called ``glass ceiling"~\citep{pachet2004improving,casey2008content}. In addition, there also exists a semantic-gap between the automatically extracted music descriptors from audio signals and the high level music concepts that humans relate to~\citep{celma2006foafing,casey2008content}. Furthermore, since the research problems undertaken in \gls{mir} have mainly shaped by the western commercial music of the past few decades~\citep{XavierSerra2011}, many of the technologies developed within \gls{mir} are not directly applicable to several music cultures of the world.  Thus, there is a need to bridge this gap and take a broader perspective to describe music by taking the cultural, social and user context into account~\citep{roadmap_mir}. It is in this context that the CompMusic project was envisioned~\citep{XavierSerra2011}.

CompMusic\footnote{http://compmusic.upf.edu/} (Computational Models for the Discovery of the World'd Music) is a research project funded by the European Research Council. The project focuses on five music traditions of the world: Hindustani (North India), Carnatic (South India), Turkish-makam (Turkey), Arab-Andalusian (Maghreb), and Beijing Opera (China). One of the main objectives of the CompMusic project is to promote and develop multicultural perspectives in \gls{mir}. In particular, the project aims to advance the research in computational description of music by identifying musically relevant problems coming from culture-specific contexts and developing domain specific approaches to solve them. Addressing the research problems in the context of diverse music cultures will not only help in advancing the knowledge in the specific cultures, but also expand the scope of current research in \gls{mir}. It can also help bridge the semantic-gap and push the glass-ceiling. 

CompMusic project follows a data-driven research methodology. The efficacy of the computational approaches are directly impacted by the quality of the data using which they are developed. Thus, one of the goals in the CompMusic project is to create quality data corpora that are representative of the performance practices of the music traditions. The corpora compiled and curated in the CompMusic project mainly comprise commercial quality audio recordings and relevant editorial metadata. 

The work presented in this dissertation is carried out as a part of the CompMusic project and aligns with its goals. In this thesis we focus on description of melodic aspects in \gls{iam} corpora. The cultural specificities of \gls{iam} have shaped our work at each step, whether it is the identification of relevant research problems, building the data corpora, or the methodology adopted by the computational approaches. The insights gained in the process of developing culture-aware and domain specific approaches will help expand the scope of the state of the art in \gls{mir}. Our work also paves way for cross-cultural studies, which can help us better understand the influence of cultural training on perception and cognition of different musical aspects.


\section{Opportunities and Challenges}
\label{sec:challenges_opportunities}
\gls{iam} is a highly evolved music tradition with its origins dating back as early as 1500\,BC, and is alive and thriving. It is a well studied music tradition with sophisticated and grounded music theory. The literature is replete with scholarly text written on musical concepts in \gls{iam}. However, this music tradition is not explored fully from a computational analysis point of view. The established musical theories and existing musicological work provides a strong base to formulate \gls{mir} tasks and develop computational models for automatic music description.

IAM is a performance centric music tradition, which has been transmitted orally across generations following a tradition of Guru-Shishya parampara (``lineage'' system). The musical compositions in IAM merely act as skeletons in music performances, and the essence of the music lies in the improvisatory aspects. As a result of which, IAM mainly possesses recorded music repertoire. 

Reliable extraction of even a low-level melody representation such as predominant pitch from recorded performances is a challenging task. As a result of which, computational approaches for melodic description in audio recordings are still primarily focused on extracting such representations and have not not been able to address the higher level melodic analyses comprehensively. Specific heterophonic characteristics of IAM make it feasible to obtain a low-level melody representation from audio recordings using current state-of-the-art pitch estimation methods. This is also indicated by the past MIREX (an international MIR evaluation campaign) results\footnote{\url{http://www.music-ir.org/mirex/wiki/MIREX_HOME}}. Compare the accuracy obtained by different algorithms on INDIAN08\footnote{\url{http://nema.lis.illinois.edu/nema_out/mirex2011/results/ame/indian08/summary.html}}, MIREX05\footnote{\url{http://nema.lis.illinois.edu/nema_out/mirex2011/results/ame/mirex05/summary.html}} and MIREX09~0dB\footnote{\url{http://nema.lis.illinois.edu/nema_out/mirex2011/results/ame/mirex09_0dB/summary.html}} datasets from MIREX-2011. The feasibility of obtaining a reasonably accurate predominant pitch representation of melody from audio recordings enables us to focus on the description of higher level melodic aspects of music performances. Thus, \gls{iam} provides an opportunity to broaden the scope of computational approaches for melodic analysis and description, much beyond describing the melodic aspects of music performances by merely their pitch contours.

Although the extraction of predominant pitch in IAM recordings is relatively less complicated, its abstraction into a symbolic representation is a challenging task. One way of abstracting a continuous pitch contour is melody transcription, which is still an ill-defined task in the case of IAM due to its meandering melodic characteristics\TODO{ref:Kaustuv}. Moreover, the process of discretizing such melodic movements often results in a loss of information relevant to characterization and description of melodies. Thus, difficulties in abstraction of a continuous melody representation in IAM poses challenges in its processing. 


There is no standard frequency that is used as a reference for tuning instruments and voice in the performances of \gls{iam}. A lead artist can choose any convenient frequency as tonic, which acts as the reference using which all accompanying instruments are tuned. Tonic pitch varies across artists and may also vary across the performances of an artist. These factors make it difficult to directly process melodies across different artists as well as across different performances of the an artist.


\begin{figure}
	\begin{center}		\includegraphics[width=\figSizeHundred]{ch01_introduction/figures/phraseClassesExample.pdf}
	\end{center}
	\caption{Pitch contours of occurrences of three different characteristic melodic phrases in Hindustani music. Contours are frequency transposed and time shifted for a better visualization.}
	\label{fig:phraseComplexityExample_intro}
\end{figure}

\textquote*[Cambouropoulos2006]{\textit{Music becomes intelligible to a great extent through self-reference, i.e.,~through the relations of new musical passages to previously heard material. Structural repetition and similarity are crucial devices in establishing such relations}}.

\textquote[schenker1980harmony]{Only by repetition can a series of tones be characterized as something definite. Only repetition can demarcate a series of tones and its purpose. Repetition thus is the basis of music as an art}. 

Analysis of repeating melodic patterns has been instrumental in the description of melodies by a large number of computational approaches in MIR. Repeating melodic patterns are integral to the melodic framework in IAM, the raga. They act as building blocks to construct melodies within the \gls{raga} grammar. Different types of melodic patterns in IAM have well defined functional roles. For example, a certain type of patterns correspond to melodic ornaments, some others form the opening line of compositions and, musically the most significant patterns are those that characterize ragas (\secref{}). Thus, IAM provides an interesting opportunity to develop computational approaches for discovery and characterization of melodic patterns from audio collections. However, the improvisatory nature of this music tradition makes this task challenging. The characteristic melodic phrases of \glspl{raga} act as the basis for artists to improvise, providing them with a medium to express creativity during \gls{raga} rendition. Artists bring in novelty through creatively transforming these melodic phrases as much as possible within the periphery defined by the \gls{raga} grammar. Therefore, the surface representation of these melodic phrases vary a lot across their occurrences. This high degree of variation in terms of the overall duration of a phrase, non-linear time warpings and the added melodic ornaments together pose a big challenge for melodic similarity computation and pattern extraction in \gls{iam}. In~\figref{phraseComplexityExample_intro} we illustrate this variability by showing the pitch contours of the different occurrences of three characteristic melodic phrases of the \gls{raga} Alaiya Bilawal. We can clearly see that the duration of a phrase across its occurrences varies a lot and the steady melodic regions are highly varied in terms of the duration and the presence of melodic ornaments. These characteristics of melodic patterns in IAM provide an opportunity to gain deeper insights into the perception of melodic similarity as well as how it is influenced by different cultural aspects. 

Discovery of melodic patterns is a computationally complex task. Given the long duration of audio recordings in IAM, some of which may even last for an hour, discovering melodic patterns using the concept of musica parallelism [EMILIOS] is a computationally challenging task.\TODO{Joan can you suggest a better way to put it?}

\cite[p. 96]{martinez2001semiosis} (original definition given by Stern, 1933);

\blockquote{The \gls{raga} is more fixed than a mode, and less fixed than the melody, beyond the mode and short of melody, and richer both than a given mode or a given melody...}

This definition is closely related to the one given by~\cite{powers1963background};

\blockquote{A \gls{raga} is not a tune, nor is it a `modal' scale, but rather a continuum with scale and tune as its extremes.}

Raga thus is a fascinating topic of research. Being a complex melodic framework it involves an intricate interplay between different melodic elements both in terms of the tonality and their temporal relations. Therefore, its computational characterization and recognition poses unique challenges as well as provides new opportunities. It is worth mentioning that recognizing raga in a musical performance requires domain expertise, which further emphasizes the complexity of the task.

IAM thus provides a context that is highly conducive to developing novel computational approaches to describe higher level melodic aspects of music, specifically of music performances in audio collections. 


\section{Scope and Objectives}
\label{sec:scope_objectives}

Analysis and description of melodic aspects of music is a broad research topic that can be approached from a number of perspectives and different academic disciplines. In this thesis we take a data-driven engineering approach and focus solely on the computational aspects of melodic analysis, making use of the established music theories. Our applied research methodology, stands at the intersection of signal processing, machine learning and time-series analysis. We focus on content-based processing, wherein the input data used in our approaches comprise mainly audio recordings, and in a few cases their associated editorial metadata. The approaches proposed in our work are developed and evaluated using music collections of \gls{iam} that includes both Hindustani and Carnatic music. We now outline our broad objectives in this dissertation.

\begin{itemize}
	\item To curate and structure a representative music corpora of \gls{iam} that comprise audio recordings and associated metadata, and use that to compile sizable and well annotated tests datasets for melodic analyses.
	\item To develop data-driven computational methodologies for discovery and characterization of musically relevant melodic patterns in sizable audio collections of \gls{iam}
	\item To devise computational approaches for automatically recognizing \glspl{raga} in recorded performances of \gls{iam}.
\end{itemize}

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\figSizeEighty]{ch01_introduction/figures/tasks.pdf}
	\end{center}
	\caption{Computational tasks within melodic analysis of \gls{iam} addressed in this dissertation.}
	\label{fig:tasks}
\end{figure}


To meet these objectives we perform a number of computational tasks as illustrated in~\figref{fig:tasks}. We first obtain a tonal context to analyze melodies by identifying the tonic pitch used in the recording (tonic identification). We detect specific melodic landmarks that demarcate melodic phrases in \gls{iam} (\gls{nyas} segmentation). Before addressing the task of melodic pattern discovery we study the efficacy of different melodic similarity measures in IAM. We then perform pattern discovery through an unsupervised methodology, and characterize the discovered patterns to identify raga motifs, which are musically the most significant patterns in \gls{iam}. Finally, we combine the outcomes of the above methods to perform \gls{raga} recognition. 

The work presented in this thesis is done as a part of the CompMusic project, and aligns with its goals. The efforts in this thesis are directed towards the bigger goal of developing culture-aware computational approaches that can utilize domain knowledge in order to produce semantically meaningful description of music. Our work also aligns with the philosophy of open-access and reproducible research. The data and the code pertaining to this thesis is made publicly available online (\appref{chap:resources}). 


\section{Organization and Outline of the thesis}
\label{sec:organization_thesis}

There are eight chapters in this thesis. However, the primary contributions are contained in four chapters, Chapter\,3 to Chapter\,6. Each of these four chapters contain one main topic of this thesis, data corpus and datasets, data pre-processing procedures, melodic pattern processing and \gls{raga} recognition. A significant amount of the content in these chapters is derived from our peer-reviewed research papers~\cite{Gulati2014Tonic,gulati2014Landmark,gulati_SITIS_2014,gulati_ICASSP2015,gulati_ISMIR_2015,gulati_communities_2016,gulatiphrase_2016,gulati_tdms_2016}. Most of the work in these papers is done in collaboration with other researchers and musicians, which is duly indicated wherever required. We now proceed to describe a detailed outline of this thesis.

In \chapref{chap:background}, we provide an overview of the music and scientific background and review relevant literature available on the topics addressed in this thesis. We begin with a short description of the terminology used in this thesis. We then provide a brief introduction to \gls{iam} and of the music concepts directly related to melodic aspects in this music tradition. We review existing research within \gls{mir} that relate to the topics covered in this dissertation. We analyze separately the literature that focuses on computational analysis of \gls{iam} and the one for other music traditions of the world. We finally present an overview of the relevant scientific background needed to better understand the technical concepts discussed in this thesis. Our main contribution in this chapter is in reviewing the relevant literature and compiling it.

In \chapref{chap:corpus_music_corpora_and_datasets}, we present an overview of the music corpora and test datasets of \gls{iam} that are compiled as a part of the CompMusic project. We enumerate the set of design criterion followed to build music corpora for research in \gls{iam}~\citep{serra:14:corpus}. We describe both Hindustani and Carnatic music corpus and present a short evaluation of the goodness of the corpora with respect to different criterion. Subsequently, a detailed description of the individual test datasets used for evaluations in this thesis is provided. The content of this chapter is derived from~\citep{serra:14:corpus,CM_Corpora_Ajay14}. Our main contributions in this chapter are in building the research corpora, which was a team effort, and compiling and annotating different test datasets with the help from musicians.

In \chapref{chap:data_preprocessing}, we describe different data pre-processing blocks employed in our work to obtain musically relevant melody representations and descriptors that will be used by the methods described in the subsequent chapters. The main goal in this chapter is to present an extensive comparative evaluation of the available tonic identification approaches to select the best approach that will be used in this work, and to present our novel method for \gls{nyas} segmentation in melodies of \gls{iam}. These two tasks primarily cover our novel contributions in this chapter. In addition, we also present an overview of the methods that we use to obtain a melody representation from audio recordings.

In \chapref{chap:melodic_pattern_processing}, we present our main contributions in melodic pattern processing in \gls{iam}. There are three related topics discussed in this chapter, melodic similarity, pattern discovery and pattern characterization. We first investigate relevant melodic similarity measures with an objective to learn the influence of different choices of melody representation, distance measure and normalization strategy on melodic similarity computation for characteristic melodic patterns of \glspl{raga}. In the process we propose a novel approach to improve melodic similarity by exploiting specific characteristics of melodies in \gls{iam}. Having learned the optimal set of procedures and system parameters in an supervised setup, we utilize this knowledge for discovering melodic patterns in audio collections of \gls{iam}, in which we follow an unsupervised methodology. Finally, we discuss a novel approach to characterize the discovered melodic patterns in order to identify the ones that correspond to \gls{raga} motifs. All four studies reported in this chapter are based on our novel contributions.

In \chapref{chap:raga_recognition}, we present the other significant part of our scientific contributions in the thesis. This chapter addresses one of the most studied topics in computational analyses of \gls{iam}, automatic \gls{raga} recognition. We propose two novel approaches for \gls{raga} recognition. Our first approach utilizes melodic patterns, which are the most prominent cues for \gls{raga} recognition used by the human listeners. We utilize the discovered melodic patterns from previous chapter and employ vector space modeling techniques to model \glspl{raga}. In our second approach we propose a novel melodic representation inspired by the concept of delay coordinates. This representation encodes both the tonal and the temporal aspects of melodies that are relevant to characterize \glspl{raga}. We perform comparative evaluations with the existing methods and show that our system outperforms state of the art by significant margins.

In \chapref{sec:applicatoins}, we present applications and a demo that are based on the research outcomes in CompMusic, which also includes the work done in this thesis. In particular, we introduce Dunya, a web-based research prototype that exposes the resarch outcomes and resources in the CompMusic project and consolidates the tools and technology developed in the project. We provide a brief description of both the interfaces, web-interface and web-API, that Dunya offers to access the content. In addition, we introduce two real-world applications; Saraga and Riyaz, that capitalize on our research outcomes in CompMusic and cater to two types of use-cases, enhance listening and music education. In order to demonstrate the outcome of our melodic pattern processing approaches more directly, we also present a web-based demo. It shows a network-based navigation across discovered melodic patterns and audio recordings. \TODO{written very roughly change it after you have more idea of that chapter}

At the end of every chapter listed above we present a summary of the results and conclusions. Finally, in \chapref{sec:conclusoins} we present the overall conclusions of this thesis work, list our main contributions and discuss possible future directions for improving melodic description of \gls{iam}. This thesis also contains three appendix sections. Appendix A, lists the publications by the author, Appendix B, present ways to access the relevant resources and Appendix C, presents the glossary of the abbreviations and other terms used in this thesis.
