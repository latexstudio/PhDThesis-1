
\chapter{Abstract}

Automatically describing contents of recorded music is crucial for interacting with large volumes of audio recordings, and for developing novel tools to facilitate music pedagogy. Melody is a fundamental facet in most music traditions and, therefore, is an indispensable component in such description. In this thesis, we develop computational approaches for analyzing high-level melodic aspects of music performances in \gls{iam}, with which we can describe and interlink large amounts of audio recordings. With its complex melodic framework and well-grounded theory, the description of \gls{iam} melody beyond pitch contours offers a very interesting and challenging research topic. We analyze melodies within their tonal context, identify melodic patterns, compare them both within and across music pieces, and finally, characterize the specific melodic context of \gls{iam}, the \glspl{raga}. All these analyses are done using data-driven methodologies on sizable curated music corpora. Our work paves the way for addressing several interesting research problems in the field of \acrlong{mir}, as well as developing novel applications in the context of music discovery and music pedagogy.

The thesis starts by compiling and structuring largest to date music corpora of the two \gls{iam} traditions, Hindustani and Carnatic music, comprising quality audio recordings and the associated metadata. From them we extract the predominant pitch and normalize by the tonic context. An important element to describe melodies is the identification of the meaningful temporal units, for which we propose to detect occurrences of \gls{nyas} \glspl{svara} in Hindustani music, a landmark that demarcates musically salient melodic patterns.

Utilizing these melodic features, we extract musically relevant recurring melodic patterns. These patterns are the building blocks of melodic structures in both improvisation and composition. Thus, they are fundamental to the description of audio collections in \gls{iam}. We propose an unsupervised approach that employs time-series analysis tools to discover melodic patterns in sizable music collections. We first carry out an in-depth supervised analysis of melodic similarity, which is a critical component in pattern discovery. We then improve upon the best possible competing approach by exploiting peculiar melodic characteristics in \gls{iam}. To identify musically meaningful patterns, we exploit the relationships between the discovered patterns by performing a network analysis. Extensive listening tests by professional musicians reveal that the discovered melodic patterns are musically interesting and significant.

Finally, we utilize our results for recognizing \glspl{raga} in recorded performances of \gls{iam}. We propose two novel approaches that jointly capture the tonal and the temporal aspects of melody. Our first approach uses melodic patterns, the most prominent cues for \gls{raga} identification by humans. We utilize the discovered melodic patterns and employ topic modeling techniques, wherein we regard a \gls{raga} rendition similar to a textual description of a topic. In our second approach, we propose the \acrlong{tdms}, a novel feature based on delay coordinates that captures the melodic outline of a \gls{raga}. With these approaches we demonstrate unprecedented accuracies in \gls{raga} recognition on the largest datasets ever used for this task.  Although our approach is guided by the characteristics of melodies in \gls{iam} and the task at hand, we believe our methodology can be easily extended to other melody dominant music traditions.

Overall, we have built novel computational methods for analyzing several melodic aspects of recorded performances in \gls{iam}, with which we describe and interlink large amounts of music recordings. In this process we have developed several tools and compiled data that can be used for a number of computational studies in \gls{iam}, specifically in characterization of \glspl{raga}, compositions and artists. The technologies resulted from this research work are a part of several applications developed within the CompMusic project for a better description, enhanced listening experience, and pedagogy in \gls{iam}.

