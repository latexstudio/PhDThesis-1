
\chapter{Abstract}

Automatically describing contents of recorded music is crucial for interacting with large volumes of audio recordings, and for developing novel tools to facilitate music pedagogy. Melody is a fundamental facet in most music traditions and, therefore, is an indispensable component in such description. In this thesis, we develop computational approaches for analyzing high-level melodic aspects of music performances in \gls{iam}, using which we can describe and interlink large amounts of audio recordings. With its complex melodic framework and well-grounded theory, the description of \gls{iam} melody beyond pitch contours offers a very interesting and challenging research topic. We analyze melodies within their tonal context, identify melodic patterns, compare them both within and across music pieces, and finally, characterize the specific melodic context of \gls{iam}, the \glspl{raga}. All these analyses are done using data-driven methodologies on sizable curated music corpora.\TODO{future outlook sentence}

The thesis starts by compiling and structuring largest to date music corpora of the two \gls{iam} traditions, Hindustani and Carnatic music, comprising quality audio recordings and the associated metadata. From them we extract the predominant pitch and normalize by the tonic context. An important element to describe melodies is the identification of the meaningful temporal units, for which we propose to detect occurrences of \gls{nyas} \glspl{svara} in Hindustani music, a landmark that demarcates musically salient melodic patterns.

Utilizing these melodic features, we extract musically relevant recurring melodic patterns. These patterns are the building blocks of melodic structures in both improvisation and composition. Thus, they are fundamental to the description of audio collections in \gls{iam}. We propose an unsupervised approach that employs time-series analysis tools to discover melodic patterns in sizable music collections. We first carry out an in-depth supervised analysis of melodic similarity, which is a critical component in pattern discovery. We then improve upon the best possible competing approach by exploiting peculiar melodic characteristics in \gls{iam}. To identify musically meaningful patterns, we exploit the relationships between the discovered patterns by performing a network analysis. Extensive listening tests by professional musicians reveal that the discovered melodic patterns are musically interesting and significant.

Finally, we utilize our results for recognizing \glspl{raga} in recorded performances of \gls{iam}. We propose two novel approaches that jointly capture the tonal and the temporal aspects of melody. Our first approach uses melodic patterns, the most prominent cues for \gls{raga} identification by humans. We utilize the discovered melodic patterns and employ topic modeling techniques, wherein we regard a \gls{raga} rendition similar to a textual description of a topic. In our second approach, we propose the \acrlong{tdms}, a novel feature based on delay coordinates that captures the melodic outline of a \gls{raga}. With these approaches we demonstrate unprecedented accuracies in \gls{raga} recognition on the largest datasets ever used for this task.  Although our approach is guided by the characteristics of melodies in \gls{iam} and the task at hand, we believe our methodology can be easily extended to other melody dominant music traditions.

Overall, we have built novel computational methods for analyzing several melodic aspects of recorded performances in \gls{iam}, with which we describe and interlink large amounts of music recordings. In this process we have developed several tools and compiled data that can be used for a number of computational studies in \gls{iam}, specifically in characterization of \glspl{raga}, compositions and artists. The technologies resulted from this research work are a part of several applications developed within the CompMusic project for a better description, enhanced listening experience, and pedagogy in \gls{iam}.


%
%%%%%%%%%%%%%%Applications of the technologies we work on: Organization, Navigation, Recommendation, Discovery, Creation, Education, Evaluation, Enhancements (listening, performance), Musicology, Other studies
%
%%%%%% What actions can be done automatically to give rise to applications above
% ()Keywords) automatic description, indexing, search, retrieval, interaction with music content 
%
%%%%%%%%%%%%%Applications/motivations of our specific tasks
%
%Tonic Identification: understanding musical concepts (drone + raga-tonic dualities etc), automatic music description, input to higher level analysis
%
%Nyas segmentation: Understanding musical concept, automatic description, input to other analyses, enhanced listening, education tool
%
%Similarity: understanding musical concept, automatic description, input to other analyses, enhanced listening, music education tools, establishing similarities and influences between artists, school of music, ragas, and recordings.... input to higher level analysis, navigation and discovery, musicological analysis, similarity based retrieval
%
%discovery: understanding musical concepts, understanding improvisation in \gls{iam}, understanding creative aspects of \gls{iam}, music generation, enhanced listening, music education tools, establishing similarities and influences between artists, school of music, ragas and recordings...input to higher level analysis, navigation and discovery, musicologial analysis, indexing, search and retrieval, similarity based retrieval
%
%Characterization: al that discovery does + understanding function roles of differnt type of patterns, 
%
%Raga recognition: understaing music, automatic description, education tool, establishing sim and inf like said above, raga based music retrieval, organization, navigation and discovery, indexing, searhc and retrieval 

%%%%%%%%%%%%%%% Different scientific areas that we use the concepts from
% Signal processing, time-series analysis, machine learning, musicology

%%%%%%%%%%%%%% Our approaches/work (adjectives) 
% Data-driven, involve both top-down and bottom-up approach, Culturally aware, human interpretable stages and results and learnings, applied research, focus on understanding than numbers, quantitative and qualitative evaluations, Knowledge driven??, domain-specific, content-based, mostly using audio signal information, 

%%%% Main goals
% Select relevant (core) problems, gather representative data, understand choices of parameters and processing steps since characteristics are so diff, understanding of challenges and opportunities in diff tasks, influence of characteistics on choices of procedure and params, influence of params and procedures on tasks, comparative eval whereever possible, compile literature, Evaluate and verify hypothesis and approaches, exploiting cultural specificities to advance!!! identify key melodic unit to describe melodies..exploiting specificities of musical culture..melodic pattern similarity, discovery and characterization, unsupervised analysis, bringing novel insights, large-scale study,  raga-recognition, quantitative evaluation of musical relevance of discovered patterns, novel melodic representation, pushing state of the art in raga recognition..taking analogies with topic modeling techniques, connection between describing a topic and rendering a raga. open data, open code, reproducibility, applications, demonstrating usefulness and potential of such technologies, 


