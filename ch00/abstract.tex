
Automatically describing different aspects of digital music content is nowadays crucial for organizing, searching and interrelating large volumes of music recordings. Melody is a fundamental facet in most music traditions, and therefore, is an indispensable component in their description. However, melodic analysis is largely limited to sheet music, and recorded performances remain underinvestigated by the computational methodologies in \gls{mir}. This is primarily due to the difficulties in obtaining a reliable melody representation from audio signals. Indian art music being heterophonic makes melody extraction from recorded performances feasible, thus allowing us to focus on musically meaningful tasks such as motivic analysis and characterization of music compositions?. With its complex melodic structures and well-grounded theory \gls{iam} also provides an opportunity to push the boundaries of the current knowledge in \gls{mir}. This thesis addresses computational analysis of melodies in \gls{iam} to describe its melodic structures, both within and across audio music recordings.

As a needed first step in data-driven methodologies, we start by compiling and curating a representative music corpora of performances in \gls{iam} that comprise quality audio recordings and associated metadata. From this audio collection we obtain relevant melody representations and descriptors with which to perform melodic analysis. We use a state-of-the-art algorithm for extracting predominant melody from polyphonic audio. Tonic pitch in performances of \gls{iam} varies across artists and their recordings, and therefore, its estimation becomes a necessary first step for a meaningful melodic analysis.  For tonic identification we use our proposed method, which outperforms existing methods as shown by our extensive comparative evaluation. For segmentation of melodies we propose to detect occurrences of nyas svaras, a landmark that demarcates musically salient melodic patterns in \gls{iam}. 

With the set of melodic features mentioned above we proceed to extract musically significant melodic patterns. These recurring patterns are the building blocks of melodic structures in both improvisation and composition, and are thus instrumental in the description of audio collections in \gls{iam}. We propose an unsupervised approach and employ time-series analysis tools to discover such patterns in sizable music collections. Due to the challenges involved in quantitatively evaluating unsupervised approaches, we first carry out an in-depth supervised analysis of  melodic similarity, which is a critical component in pattern discovery. We improve upon the best methodology for melodic similarity that we identify through an exhaustive evaluation of different procedures and their parameter settings that are well known and widely used for this task. We improve melodic similarity by exploiting characteristics that are peculiar to melodies in \gls{iam}. Computational pattern discovery typically results in large amounts of musically trivial patterns. We propose an approach to identify musically significant patterns by performing a network analysis that exploits the interaction between the discovered patterns. Listening tests reveal that the discovered melodic patterns from this approach are musically interesting and significant.

Finally, all the features obtained so far, melody representations, melodic descriptors and discovered patterns are utilized by our proposed methods for recognizing \glspl{raga} in recorded performances of \gls{iam}. Raga is a core musical concept in \gls{iam}, used in composition, performance, music organization, and pedagogy, and therefore, the most desired melodic description of a music recording. We propose two novel approaches for raga recognition that jointly capture the tonal and the temporal aspects of melody. Our first approach is based on melodic patterns, the most prominent cues for raga identification by humans. For this, we utilize the discovered melodic patterns and employ topic modeling techniques, in which we regard a \gls{raga} rendition similar to a textual description of a topic. In our second approach we propose the \gls{tdms}, a novel feature based on delay coordinates that captures the melodic outline of a \gls{raga}. With these approaches we demonstrate unprecedented accuracies in \gls{raga} recognition on the largest datasets ever used for this task.  Although our approach is guided by the characteristics of melodies in \gls{iam} and the task at hand, we believe our methodology can be easily extended to other melody dominant music traditions.

In this thesis we have built novel computational methods for melodic analysis of iam, using which  we can describe and interlink large quantity of music recordings. In this process we have developed tools and compiled data that can be used for a number of computational studies in \gls{iam}, specifically for characterization of ragas, compositions and artists. The technologies resulting from this research work are a part of several applications developed within the CompMusic project for a better description, enhanced listening experience, and pedagogy in \gls{iam}.

%
%%%%%%%%%%%%%%Applications of the technologies we work on: Organization, Navigation, Recommendation, Discovery, Creation, Education, Evaluation, Enhancements (listening, performance), Musicology, Other studies
%
%%%%%% What actions can be done automatically to give rise to applications above
% ()Keywords) automatic description, indexing, search, retrieval, interaction with music content 
%
%%%%%%%%%%%%%Applications/motivations of our specific tasks
%
%Tonic Identification: understanding musical concepts (drone + raga-tonic dualities etc), automatic music description, input to higher level analysis
%
%Nyas segmentation: Understanding musical concept, automatic description, input to other analyses, enhanced listening, education tool
%
%Similarity: understanding musical concept, automatic description, input to other analyses, enhanced listening, music education tools, establishing similarities and influences between artists, school of music, ragas, and recordings.... input to higher level analysis, navigation and discovery, musicological analysis, similarity based retrieval
%
%discovery: understanding musical concepts, understanding improvisation in \gls{iam}, understanding creative aspects of \gls{iam}, music generation, enhanced listening, music education tools, establishing similarities and influences between artists, school of music, ragas and recordings...input to higher level analysis, navigation and discovery, musicologial analysis, indexing, search and retrieval, similarity based retrieval
%
%Characterization: al that discovery does + understanding function roles of differnt type of patterns, 
%
%Raga recognition: understaing music, automatic description, education tool, establishing sim and inf like said above, raga based music retrieval, organization, navigation and discovery, indexing, searhc and retrieval 

%%%%%%%%%%%%%%% Different scientific areas that we use the concepts from
% Signal processing, time-series analysis, machine learning, musicology

%%%%%%%%%%%%%% Our approaches/work (adjectives) 
% Data-driven, involve both top-down and bottom-up approach, Culturally aware, human interpretable stages and results and learnings, applied research, focus on understanding than numbers, quantitative and qualitative evaluations, Knowledge driven??, domain-specific, content-based, mostly using audio signal information, 

%%%% Main goals
% Select relevant (core) problems, gather representative data, understand choices of parameters and processing steps since characteristics are so diff, understanding of challenges and opportunities in diff tasks, influence of characteistics on choices of procedure and params, influence of params and procedures on tasks, comparative eval whereever possible, compile literature, Evaluate and verify hypothesis and approaches, exploiting cultural specificities to advance!!! identify key melodic unit to describe melodies..exploiting specificities of musical culture..melodic pattern similarity, discovery and characterization, unsupervised analysis, bringing novel insights, large-scale study,  raga-recognition, quantitative evaluation of musical relevance of discovered patterns, novel melodic representation, pushing state of the art in raga recognition..taking analogies with topic modeling techniques, connection between describing a topic and rendering a raga. open data, open code, reproducibility, applications, demonstrating usefulness and potential of such technologies, 


