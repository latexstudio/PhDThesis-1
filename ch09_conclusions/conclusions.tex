%!TEX root = ../thesis_a4.tex
\chapter{Summary and Future Perspectives}
\label{chap:summary_future_work}

\section{Introduction}
\label{sec:summary_thesis}

In this thesis, we have presented a number of computational approaches for analyzing melodic elements at different levels of melodic organization in \gls{iam}. In tandem, these approaches generate a high-level melodic description of the audio collections in this music tradition. They build upon each other to finally allow us to achieve the goals that we set at the beginning of this thesis, which are: 

\begin{itemize}
	\item To curate and structure representative music corpora of \gls{iam} that comprise audio recordings and the associated metadata, and use that to compile sizable and well annotated tests datasets for melodic analyses.
	\item To develop data-driven computational approaches for the discovery and characterization of musically relevant melodic patterns in sizable audio collections of \gls{iam}
	\item To devise computational approaches for automatically recognizing \glspl{raga} in recorded performances of \gls{iam}.
\end{itemize}

Based on the results presented in this thesis, we can now say that our goals are successfully met. We started this thesis by presenting our motivation behind the analysis and description of melodies in \gls{iam}, highlighting the opportunities and challenges that this music tradition offers within the context of music information research and the compmusic project (\chapref{chap:intro}). We provided a brief introduction to \gls{iam} and its melodic organization,  and critically reviewed the existing literature on related topics within the context of \gls{mir} and \gls{iam} (\chapref{chap:background}).

In~\chapref{chap:corpus_music_corpora_and_datasets}, we provided a comprehensive overview of the music corpora and datasets that were compiled and structured in our work as a part of the CompMusic project. To the best of our knowledge, these corpora comprise the largest audio collections of \gls{iam} along with curated metadata and automatically extracted music descriptors that is available for research. Furthermore, the datasets that we built from these corpora allowed us to successfully evaluate our computational approaches, with some of them being the largest datasets ever used for such evaluations. We described and evaluated the approaches we follow to obtain different melodic descriptors and melody representations with which we perform melodic analysis in this thesis (\chapref{chap:data_preprocessing}).

In~\chapref{chap:melodic_pattern_processing}, we argued that the potential of a pattern-based melodic analysis in \gls{iam} can be exploited using an unsupervised approach to extract melodic patterns from audio recordings. We demonstrated that using our novel approach we can successfully discover musically significant melodic patterns in hundreds of hours of audio collections of \gls{iam}. Importantly, our approach does not require any exemplars of melodic patterns from experts as input. In~\chapref{chap:raga_recognition}, we described two novel approaches for \gls{raga} recognition that jointly utilize the tonal and the temporal characteristics of melodies in \gls{iam} without discretizing the melody representation. We demonstrated that our approach can effectively utilize the discovered melodic patterns for \gls{raga} recognition. We also presented our approach that abstracts a continuous melody representation to capture the melodic outline relevant for characterizing \glspl{raga}. Using this approach, we demonstrated unprecedented accuracies in the task of \gls{raga} recognition using largest datasets ever used for this task. 

We note that the approaches we propose to perform these tasks are not 100\% accurate, and there exists a large scope for improvement. However, we have seen that a majority of the errors made by our approaches can be explained from a musicological and perceptual perspective. The cases where the system fails are often the ones which are challenging even for a human listener. 

Note that, here we have only provided an overall summary of the thesis. The key results and conclusions of the work presented in each chapter are summarized at the end of the chapter itself. In the subsequent section, we enumerate our main contributions (\secref{sec:summary_contributions}), and finally, end the thesis with discussions about the future perspectives (\secref{sec:future_directions}). 


\section{Summary of Contributions}
\label{sec:summary_contributions}
We now present a summary of the main contributions of this thesis.

\subsection*{Contributions to Creating Music Corpora and Datasets}

One of the objectives of the CompMusic project was to build a high quality research corpora of \gls{iam}, with which to study different computational tasks in the context of \gls{mir}. The task of compiling and curating the research corpora and different test datasets has mainly been a team effort. We describe below some specific contributions from the author. 

\begin{itemize}
	
	\item The contributions to compiling corpora are mainly in Hindustani music corpus, starting from the procurement of music CDs, ripping and structuring the audio collection and manually adding all the editorial metadata to MusicBrainz (\secref{sec:corpus_compmusic_research_corpora}). 
	
	\item Compiling and annotating CompMusic Tonic Datasets (\acrshort{tds_cm1}, \acrshort{tds_cm2} and \acrshort{tds_cm3}), which collectively include tonic annotations for 716 audio recordings spanning \TODO{XX}\,hours of audio (\secref{sec:corpus_test_datasets}). 
	
	\item Compiling and annotating a \Gls{nyas} Dataset (\acrshort{nds_cm}), which includes annotations of \gls{nyas} segments for 20 audio recordings spanning 1.5\,hours of audio, done in collaboration with Kaustuv Kanti Ganguli (\secref{sec:corpus_nyas_dataset}). 
	
	\item Improving over the existing Melodic Similarity Dataset (\acrshort{msds}), which originally included 497 annotated instances of 10 different melodic patterns in 33\,audio recordings~\citep{}\TODO{refs}. In the revised version after a detailed verification, 127\,new instances of melodic patterns were added. This is done in collaboration with Kaustuv Kanti Ganguli and Vignesh Ishwar (\secref{sec:corpus_melodic_similarity_dataset}).
	
	\item Building \Gls{raga} Recognition Datasets for Carnatic music (\acrshort{rrds_cmd_big}), and Hindustani music (\acrshort{rrds_hmd_big}), which contain \gls{raga} labels and associated editorial metadata. \acrshort{rrds_cmd_big} comprises 480 recordings in 40\,\glspl{raga} spanning 124\,hours of audio. \acrshort{rrds_hmd_big} comprises 300 recordings in 30\,\glspl{raga} spanning 116\,hours of audio. To date, these are the largest datasets ever built for studying this task, and we make them publicly available. These datasets are built in collaboration with Vignesh Ishwar and Kaustuv Kanti Ganguli (\secref{sec:corpus_raga_recognition_datasets}).
	
\end{itemize}

\subsection*{Scientific Contributions}

\begin{itemize}
	
	\item Review of the current approaches for tonic identification, melodic pattern processing and \gls{raga} recognition in the context of \gls{mir} in \gls{iam}, emphasizing their limitations and identifying avenues for scientific contributions (\secref{sec:background_relevant_work_iam}).
	
	\item Comprehensive assessment of different tonic identification approaches on a number of sizable datasets,  along with a detailed error analysis for different types of music material (\secref{sec:data_preprocessing_tonic_identification}).
	
	\item Development of a novel \gls{nyas} landmark-based approach for the segmentation of melodies in Hindustani music. \Gls{nyas} detection is addressed for the first time from a computational perspective (\secref{sec:pre_processing_nyas_segmentation}).
	
	\item In depth evaluation of different procedures and parameter settings for computing melodic similarity in the context of short-duration \gls{raga} motifs in \gls{iam} (\secref{sec:patterns_evaluation_of_similarity_measures}). 
	
	\item A partial transcription and complexity weighting-based approach for improving melodic similarity that exploits the presence of long held \glspl{svara} and \glspl{gamaka} in melodies of Hindustani and Carnatic music, respectively (\secref{sec:patterns_improving_melodic_similarity}).
	
	\item Demonstration of the utility of an unsupervised approach for discovering repeated melodic patterns in sizable audio collections of \gls{iam} (\secref{sec:patterns_melodic_pattern_discovery}).
	
	\item Characterization of the discovered melodic patterns by employing network analysis tools to identify musically significant patterns, the \gls{raga} motifs (\secref{sec:patterns_characterization_of_melodic_patterns}). 
	
	\item Development of a novel pattern-based approach for \gls{raga} recognition, which employs vector space modeling concepts to exploit discovered melodic patterns for this task (\secref{sec:pattern_based_raga_recognition}). 
	
	\item Development of  a novel feature, the \acrfull{tdms}, which captures both the tonal and the short-time temporal characteristics of a melody. This feature together with a simple \gls{1nn} classification strategy is shown to outperform state of the art in \gls{raga} recognition using the largest datasets ever used for this task (\secref{sec:tdms_raga_recognition}). 
	
\end{itemize}

\subsection*{Technical Contributions}

\begin{itemize}
	\item Building a web-based demo for navigating through the melodic patterns discovered by our approach organized by artitst, releases and recordings (see \figref{fig:browser_patterns}). 
	\item Building a web-based demo for visualizing relationships between different audio recordings based on the similarity between the constituent melodic patterns. The relationships are represented in the form of a network of melodic patterns (see \figref{fig:network_patterns}).
	\item Building a web prototype of a real-time \gls{raga} recognition system, \gls{ragawise}. This work is done in collaboration with Kaustuv K. Ganguli, Swapnil Gupta and Ajay Srinivasamurthy (\secref{sec:ragawise}).
	\item Developing two mobile applications; \gls{saraga}, which provides enhanced listening experience, and \gls{riyaz}, which facilitates pedagogy in the context of \gls{iam}. It is a team effort, with author's main contributions in the conceptualization and design of the applications, as well as in the implementation of some of the components (\secref{sec:mobile_apps_camut}).
	\item Implementation of our tonic identification algorithm (\acrshort{tonicid_justin}) in Essentia, an audio feature extraction library.		
\end{itemize}

The links to access the demos and the applications mentioned above are provided in~\appref{app:resources}.

Most of the outcomes of the work presented in this document have been published in the form of papers in international conferences and journals. The full list of the author’s publications is provided in~\appref{app:mypapers}. The compiled music corpora and the developed code and tools during our work are made publicly available to facilitate reproducible research and comparative studies (\appref{app:resources}). The set of tools and output of our approaches are also integrated in Dunya, a system that consolidates the corpora and computational tools developed in the project (\secref{sec:applications_dunya}).


\section{Future Perspectives}
\label{sec:future_directions}

To the best of our knowledge, this is the first time that melodies in \gls{iam} are computationally analyzed on corpora comprising hundreds of hours of audio recordings. This opens up several unexplored research problems that can be addressed by utilizing the results and resources presented in this thesis. In addition, there are several ways to further improve the methodologies proposed in our work. In this section, we discuss a number of these future directions. 

We start by enumerating different avenues for improvement in the pattern processing methodologies discussed in our work. In~\chapref{chap:melodic_pattern_processing}, we argued that the potential of pattern-based analysis and description of melodic aspects in \gls{iam} can be exploited by going beyond supervised methodologies for pattern processing. We successfully demonstrated the effectiveness and utility of an unsupervised approach for discovering melodic patterns. However, the lack of a quantitative assessment of such an approach limits its improvement. We believe that a balanced combination of both supervised and unsupervised methodologies would take pattern processing in \gls{iam} to the next level. One of the ways in which both these approaches can be combined is by using the output of the unsupervised approach for facilitating annotations of large amounts of melodic patterns, which is one of the biggest limitations of supervised approaches as commented in~\secref{sec:patterns_introduction}. A possible way to achieve this is to mark every melodic pattern pair (the output of our approach) as melodically similar or dissimilar. Since our method produces millions of such melodic pattern pairs in the sorted order of their melodic similarity, this can readily lead to a large corpus of melodic patterns annotated in terms of the melodic similarity between them.

With sizable annotated datasets, comprising thousands of melodic patterns across different artists, compositions, forms, and \glspl{raga}, several valuable insights into perception of melodic similarity can be obtained. We provide here some concrete examples of such analyses. One of our learnings while working on the melodic similarity is that not every sample in the string representation of a melodic pattern contributes equally in establishing similarity. There are specific regions and characteristic pitch movements in melodic patterns that are more important and often become the anchor points in determining similarity. A sizable annotated dataset of melodic patterns can facilitate such investigations, which in turn would improve models for computing melodic similarity. Another interesting and important aspect to explore in pattern discovery is to take into account the local melodic context of a pattern. Since melodies in \gls{iam} are constructed in accordance with the \gls{raga} grammar, \gls{raga} motifs might bear a strong correlation with their melodic context, which can be exploited to improve pattern discovery and also reduce its computational complexity. In addition, determining possible relations between the \gls{sama} locations (downbeat in rhythm cycle) and the locations of \gls{raga} motif is also an interesting subject of future investigations. All these analyses can benefit immensely from a well annotated sizable dataset of melodic patterns.

In our work we considered the predominant pitch in audio as the low-level melody representation. However, as illustrated by an example in~\secref{sec:data_preprocessing_predominant_melody_estimation}, timbral and loudness dimensions of melody also influence melodic similarity. Therefore, a possible future investigation is to find ways to incorporate these dimensions in the representation of melodies.

Addressing issues related with computational complexity is fundamental in pattern processing tasks. There are several strategies to make this process more computationally efficient. One of the ways is to devise an enriched melody transcription approach that can parametrically encode different types of melodic ornaments, \glspl{gamaka} and other melodic atomic units (for instance, \cite{widdess1994involving,rao1999raga}). Such a melody representation will not only make pattern processing computationally less demanding, but can also help improve melodic similarity as melodic elements can be appropriately weighted.

A processing step that is crucial in melodic analysis and is unexplored from a computational perspective in the context of \gls{iam} is melody segmentation. We showed in~\secref{sec:patterns_melodic_similarity_results_discussions} that a meaningful segmentation can tremendously improve melodic similarity computation. However, despite its importance, there are very few studies that address this task. This can be attributed to the difficulties involved in its formulation, specifically in a continuous predominant pitch representation of melody. One of the ways in which segmentation is studied is through music parallelism~\citep{Cambouropoulos2006,rodriguez2014comparing}. Since the boundaries of repeated melodic patterns can indicate possible boundaries of segmentation, the discovered melodic patterns from our approach can be utilized to study the task of melody segmentation.   

One main limitation of our proposed approach for pattern discovery is that it works with fixed duration patterns. This is mainly due to the constraints imposed by the \gls{dtw} lower-bounding techniques, and also due to the unavailability of reliable melody segmentation approaches. However, once the patterns are discovered, their boundaries can be refined. This can be done by collectively analyzing closely related melodic patterns by extending their boundaries in both directions using a dynamic programming approach similar to~\cite{muscariello2009variability}.

We commented in~\secref{sec:patterns_characterization_of_melodic_patterns} that several communities in melodic pattern network that comprise a large number of nodes often correspond to the \glspl{gamaka} type patterns. In several melodic analyses such patterns might not be useful. In such cases, \gls{gamaka} type patterns can be filtered out during the pre-processing stage, similar to the filtering step we perform for removing pattern candidates that comprise only single \gls{svara}. This would lead to more number of musically relevant melodic patterns in the output of the pattern discovery system. In addition, this procedure will also reduce the computational complexity of the system.

We now proceed to provide some future directions of research in the context of automatic \gls{raga} recognition. We saw in~\secref{sec:tdms_results_and_discussion} that the accuracies of existing approaches are around 90\%. These evaluations are performed using full length audio recordings. One of the next steps is to analyze the minimum duration of the audio recording needed to perform this task (\cite{balkwill1999cross}). Such an investigation would provide useful insights in to the applicability of these approaches in the context of real-time \gls{raga} recognition. In our recent study in~\cite{kaustuv_ismir_2016} we found that different \glspl{svara} of a \gls{raga} in a melody are explored linearly over the course of the entire music performance. This implies that a segment of audio recording taken from the start might not contain all the \glspl{svara} in the \gls{raga}, which can severely deteriorate performance of the \gls{pcd}-based approaches. This aspect of the minimum melodic material required for a reliable \gls{raga} recognition can be explored in the future. 

Existing approaches mainly capitalize solely on a single type of musical characteristics, which is typically either svara distribution, or sequence modeling or pattern (\tabref{tab:raga_recognition_methods_melodic_characteristics}). A possible direction is to combine multiple approaches for \gls{raga} recognition that utilize different types of information about melody. Our results show that the errors made by \gls{pcd}-based approach \acrshort{sotaChordia} and phase based approach \acrshort{ragarecVSM}  are complementary. Thus, they can potentially be combined to improve performance. In addition, a hierarchical model that combines these approaches based on the importance on the melodic features can be a promising methodology for \gls{raga} recognition in the future.

We now proceed to enumerate some novel research problems in the context of \gls{iam} that can utilize the output of our research work presented in this thesis. Being an improvisatory music tradition, it is interesting to study the influence of a teacher’s style on the stylistic nuances of their students and other artists. Since melodic patterns act as the  basis for constructing melodies, such an analyses can benefit immensely from the melodic patterns discovered using our approach. In addition, using melodic patterns one can perform a corpora level characterization of compositions and \glspl{raga}. Such a characterization will, in turn, help define novel ways to establish similarity measures between artists, compositions and \gls{raga}.

The improvisatory nature of \gls{iam} also makes the study of the temporal evolution of melody in a music piece a relevant topic of research. This can be achieved through an intra-recording analysis based on melodic patterns, such as analyzing the degree of pitch and timing transformations across the occurrences of melodic patterns, the time difference between the adjacent recurrences of a melodic pattern and the chronology of the occurrence of melodic patterns. Such insights will help understand the nature of improvisatory \gls{raga} rendition in general and the related artist specific stylistic nuances.

 Analysis of different melodic elements presented in our work can be combined within an ontological framework to build a knowledge base of these melodic aspects in \gls{iam}. This in turn can be utilized to develop applications that perform high-level musicological queries. Such a system can also enable a number of applications that address pedagogical needs in the context of the \gls{iam}. These applications can provide an objective description of the melodic structures in  the recorded performances such as, the overall progression of melody in a piece, time-synchronized display of different melodic units, and relationship between these units across artists, \glspl{raga}, and compositions. Specifically in the context of \gls{iam}, where the music nuances are learned implicitly through years of training, such a description of melodic aspects can be immensely helpful to music students in learning from the recorded performances of maestros.


