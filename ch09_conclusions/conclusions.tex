%!TEX root = ../thesis_a4.tex

\chapter{Summary and Future Perspectives}
\label{chap:summary_future_work}

\section{Introduction}
\label{sec:summary_thesis}

 In this thesis we have presented computational approaches for analyzing a number of melodic elements at different levels of melodic organization in \gls{iam}, which in tandem generate a higher-level melodic description of its audio collections. These approaches build upon each other to finally allow us to achieve the goals that we set at the beginning of this thesis, which are: 
 
 \begin{itemize}
 	\item To curate and structure a representative music corpora of \gls{iam} that comprise audio recordings and associated metadata, and use that to compile sizable and well annotated tests datasets for melodic analyses.
 	\item To develop data-driven computational approaches for discovery and characterization of musically relevant melodic patterns in sizable audio collections of \gls{iam}
 	\item To devise computational approaches for automatically recognizing \glspl{raga} in recorded performances of \gls{iam}.
 \end{itemize}
 
 Based on the results presented in this thesis we can now say that our goals are successfully met. In~\chapref{chap:corpus_music_corpora_and_datasets} we provided a comprehensive overview of the music corpora and datasets that were compiled and structured in our work as a part of the CompMusic project. To the best of our knowledge these corpora comprise the largest audio collections of \gls{iam} along with curated metadata and automatically extracted music descriptors that is available for research. Furthermore, the datasets that we built from these corpora allowed us to successfully evaluate our computational approaches, with some of them being the largest datasets ever used for such evaluations. 
 
 In~\chapref{chap:melodic_pattern_processing} we argued that the potential of a pattern-based melodic analysis in \gls{iam} can be exploited using an unsupervised approach to extract melodic patterns from audio recordings. We demonstrated that using our novel approach we can successfully discover musically significant melodic patterns in hundreds of hours of audio collections of \gls{iam} without requiring any exemplars of melodic patterns from experts as input.
 
 In~\chapref{chap:raga_recognition} we described two novel approaches for \gls{raga} recognition that jointly utilize the tonal and the temporal characteristics of melodies in \gls{iam} without discretizing the melody representation. We demonstrated that our approach can effectively utilize the discovered melodic patterns for \gls{raga} recognition. We also presented our approach that abstracts continuous melody representation to capture the melodic outline relevant for characterizing \glspl{raga}. Using this approach we demonstrated unprecedented accuracies in the task of \gls{raga} recognition using largest datasets ever used for this task. 
 
 We note that the approaches we propose to perform these tasks are not 100\% accurate, and there exists a large scope for improvement. However, a significant part of the errors made by our approaches can be explained from a musicological and perceptual perspective. The cases where the system fails are often the ones which are challenging even for a human listener. 
 
 We started this thesis by presenting our motivation behind the analysis and description of melodies in \gls{iam}, highlighting the opportunities and challenges that this music tradition offers within the context of music information research and the compmusic project (\chapref{chap:intro}). We provided a brief introduction to \gls{iam} and its melodic organization,  and reviewed the existing literature on related topics within the context of \gls{mir} and \gls{iam} (\chapref{chap:background}). We described the music corpora of \gls{iam} and different test datasets, emphasizing the design criterion taken in the Compmusic project to compile and curate the corpora (\chapref{chap:corpus_music_corpora_and_datasets}).  We described and evaluated the approaches we follow to obtain melodic descriptors and melody representations with which we perform melodic analysis in this thesis (\chapref{chap:data_preprocessing}). We then presented and evaluated our approaches for computing melodic similarity, discovering melodic patterns and characterizing melodic patterns (\chapref{chap:melodic_pattern_processing}). Finally, we presented and evaluated our novel approaches for \gls{raga} recognition that utilize discovered melodic patterns and abstracted melody representation to outperform the state-of-the-art (\chapref{chap:raga_recognition}).
 
 At the end of each chapter in this thesis we included a section that summarized the key results and conclusions of the work reported in that chapter. We here provide an overall summary of the thesis, highlight our main contributions (\secref{sec:summary_contributions}), and finally, end the thesis with some discussions about the future perspectives (\secref{sec:future_directions}). 
 
 
\section{Summary of Contributions}
\label{sec:summary_contributions}
We now present a summary of the main contributions of this thesis.

\subsubsection*{Contributions to Creating Music Corpora and Datasets}

One of the objectives of the CompMusic project was to build a quality research corpora of \gls{iam}, with which to study different computational tasks in the context of \gls{mir}. The task of compiling and curating the research corpora and different test datasets has mainly been a team effort. We describe below some specific contributions from the author. 

\begin{itemize}
	
	\item The contributions to compiling corpora are mainly in Hindustani music corpus (\secref{sec:corpus_hindustani_music_corpus}), starting from the procurement of music CDs, ripping and structuring the audio collection and manually adding all the editorial metadata to MusicBrainz. 
	
	\item Compiling CompMusic Tonic Datasets (\acrshort{tds_cm1}, \acrshort{tds_cm2} and \acrshort{tds_cm3}), which collectively include tonic annotations for 716 audio recordings spanning. \TODO{Double check this number}
	
	\item Compiling \Gls{nyas} dataset (\acrshort{nds_cm}), which includes annotations of \gls{nyas} segments for 20 audio recordings spanning 1.5\,hours of audio, done in collaboration with Kaustuv Kanti Ganguli. 
	\item Improving Melodic Similarity Dataset (\acrshort{msds}), which originally included 497 annotated instances of 10 different melodic patterns in 33\,audio recordings done by Kaustuv Kanti Ganguli and Vignesh Ishwar. In the revised version of the dataset that came after a detailed verification, 127\,instances of melodic patterns were added for the same audio recordings and pattern categories. 
	\item Compiling \Gls{raga} recognition datasets (\acrshort{rrds_cmd_big} and \acrshort{rrds_hmd_big}), which contain \gls{raga} labels and associated editorial metadata for 780\, audio recordings, done in collaboration with Vignesh Ishwar and Kaustuv Kanti Ganguli. \acrshort{rrds_cmd_big} comprise 480\,full length recorded performances in 40\,\glspl{raga} with 12 recordings per \gls{raga} spanning a total of 124\,hours of audio. \acrshort{rrds_hmd_big} comprise 300\,full length recorded performances in 30\,\glspl{raga} with 10 recordings per raga spanning a total of 130\,hours of audio.
\end{itemize}

\subsection*{Scientific and Technical Contributions}

\begin{itemize}
	\item Review of current approaches for tonic identification, melodic pattern processing and \gls{raga} recognition in the context of \gls{mir} in \gls{iam}, emphasizing their limitations and identifying avenues for scientific contributions.
	\item Comprehensive assessment of different tonic identification approaches on a number of sizable datasets,  along with a detailed error analysis for different types of music material.
	\item Development of a novel \gls{nyas} landmark-based approach for the segmentation of melodies in Hindustani music. \Gls{nyas} detection is addressed for the first time from a computational perspective.
	\item In depth evaluation of different procedures and parameter settings for computing melodic similarity in the context of short-duration \gls{raga} motifs in \gls{iam}. 
	\item A partial transcription and complexity weighting-based approach for improving melodic similarity is devised that exploits peculiar characteristics of melodies in \gls{iam} .
	\item Demonstration of the utility of an unsupervised approach for discovering repeated melodic patterns in sizable audio collections of \gls{iam}.
	\item Characterization of the discovered melodic patterns by employing network analysis tools to identify musically significant patterns, the \gls{raga} motifs. 
	\item Demonstration of the utility of a novel pattern-based approach for \gls{raga} recognition, which employs vector space modeling concepts to exploit discovered melodic patterns for this task. 
	\item Development of  a novel feature, the \acrfull{tdms}, which captures both the tonal and the short-time temporal characteristics of a melody. This feature together with a simple \gls{1nn} classification strategy is shown to outperform state of the art in \gls{raga} recognition using the largest datasets ever used for this task. 
\end{itemize}

Most of the outcomes of the work presented in this document have been published in the form of papers in international conferences, and journals. The full list of the authorâ€™s publications is provided in~\appref{app:publications}. The code and tools developed during our work are made publicly available to facilitate reproducible research and comparative studies (). The set of tools and output of our approaches are also integrated in Dunya, a system that consolidates the corpora and computational tools for XXX. There are a number of online Web demos built to demonstrate the usefulness of the outcome of our approaches, which are discussed in~\secref{}. Furthermore, we have also exploited a number of the outcomes of our work for developing mobile applications that provide enhanced listening experience, and novel pedagogical tools in the context of \gls{iam} \secref{}.

\TODO{Any overall big sentence, that we have opened out research area? Good datasets and spectrum of problems.}

\section{Future Perspectives \TODO{REPHRASE, WORK REMAINING}}
\label{sec:future_directions}

There are several directions for future work in both improving the methodologies described in this thesis, and addressing unexplored research problems that can utilize our results and resources. The music corpora compiled and curated in the CompMusic project provides a strong base to address a variety of such research problems in the future.

We start with enumerating different avenues for improvement in the patten processing methodologies discussed in our work. In~\chapref{chap:melodic_pattern_processing} we argued that the potential of pattern-based analysis and description of melodic aspects in \gls{iam} can be exploited by going beyond supervised methodologies for pattern processing. We successfully demonstrated the effectiveness and utility of an unsupervised approach for discovering melodic patterns. However, lack of a quantitative assessment of such an approach hampers its improvement. We believe that a balanced combination of both supervised and unsupervised methodologies would take pattern processing in \gls{iam} to the next level. One of the ways in which both these approaches can be combined is by using the output of the unsupervised approach for facilitating annotations of large amounts of melodic patterns. The biggest limitations of the supervised approaches as mentioned in~\secref{sec:patterns_introduction} are the difficulties in annotating large datasets and the presence of human bias in the annotations, resulting in only certain type of melodic patterns. Both these issues can be addressed to a large extent by utilizing the outcome of pattern discovery approach for annotations.

With sizable annotated datasets of melodic patterns several valuable insights into perception of melodic similarity can be obtained. By sizable dataset we mean thousands of melodic patterns across different artists, compositions, forms, and \glspl{raga}. We here provide some concrete examples of analyses that can be done with such datasets. One of our learnings while working on the melodic similarity is that not every sample in the string representation of a melodic pattern contributes equally in establishing similarity. There are specific regions and characteristic pitch movements in the melodic patterns that are more important and often become the anchor points in determining similarity. Note that this observation is based on our informal discussions with musicians and this phenomenon is yet to be scientifically studied. A sizable corpora of melodic patterns can facilitate such investigations, which in turn would improve models for computing melodic similarity. Another interesting and important aspect to explore in pattern discovery is to take into account the local melodic context of a pattern. Since melodies in \gls{iam} are constructed in accordance with the \gls{raga} grammar, \gls{raga} motifs might bear a strong correlation with their melodic context, which can be exploited it to improve pattern discovery and and reduce its computational complexity. In addition, determining possible relation between the \gls{sama} locations (downbeat in rhythm cycle) and the locations of \gls{raga} motif is also an interesting subject of future investigations. All these analyses can benefit immensely from a well annotated sizable dataset of melodic patterns. 

In our work we considered the predominant pitch extracted from audio recording as the low-level melody representation. However, as illustrated by an example in~\secref{sec:data_preprocessing_predominant_melody_estimation}, timbral and loudness dimensions of melody also influence melodic similarity. Therefore, a clear direction of future investigation is to find ways to incorporate these dimensions in the representation of melodies.

Addressing issues related with computational complexity is fundamental in pattern processing tasks. In our work, since it was the first time when melodic pattern discovery was performed on such a scale for \gls{iam}, we did not impose much top-down musical knowledge and applied brute-force approach to obtain all possible repeating melodic patterns. However there can be several strategies to make this process more computationally efficient. One of the ways is to devise an enriched melody transcription approach that can parametrically encode different types of melodic ornaments, \glspl{gamaka} and other melodic atomic units. Such a melody representation will not only make pattern processing computationally less demanding, but can also help improve melodic similarity as melodic elements can be appropriately weighted. Some initial work in this direction is done by xXXX.

A processing step that is crucial in melodic analysis and is not worked upon much in the context of \gls{iam} is melody segmentation. We showed in Section XX that a meaningful segmentation can tremendously improve melodic similarity computation. However, despite the importance, there are very few studies that address this task. This can be attributed to the difficulties involved in its formulation, specifically in the case of a continuous predominant pitch representation of melody. One of the ways in which segmentation is studied is through music parallelism. The boundaries of the discovered melodic patterns can indicate possible boundaries of segmentation REF. Thus, the output of our work can be utilized to study the task of melody segmentation.  

One main limitation of our proposed approach for pattern discovery is that it works with fix duration patterns. This is mainly due to the constraints posed by the \gls{dtw} lower-bounding techniques, and also due to the unavailability of reliable segmentation approaches. However, once the patterns are discovered their boundaries can be refined and, melodic similarity across patterns can be recomputed to identify and remove noisy matches. The boundaries of closely related melodic patterns can be collectively analyzed to extend them in both directions using a dynamic programming approach XXX.

We commented in Section XX that several communities with a large number of nodes often comprise patterns that correspond to the \glspl{gamaka}. In several melodic analyses such patterns might not be useful. In such cases, \gls{gamaka} type patterns can be filtered out during the pre-processing stage, similar to the filtering step we perform for removing pattern candidates that comprise only single \gls{svara}. 

We now proceed to provide some future directions for improving approaches for \gls{raga} recognition. We saw in Section XX that the accuracies of existing approaches are around to 90\%. These evaluations are performed using full length audio recordings. One of the next steps is to analyze the minimum duration of the audio recording needed to perform this task. Such an investigation would also provide insights into the applicability of these approaches in the context of real-time raga recognition. In our recent study in XX we found that different \glspl{svara} of a \gls{raga} in a melody are explored linearly over the course of the entire music performance. This implies that a segment of audio recording taken from the start might not contain all the \glspl{svara} in the \gls{raga}, which can severely deteriorate performance of the \gls{pcd}-based approaches. This aspect of the minimum melodic material for raga recognition can be explored in the future. 

Existing approaches mainly capitalize on a single type of muscial characteristics, either svara distribution, or sequence modeling or pattern. Another promising direction is to combine multiple approaches for \gls{raga} recognition that utilize different types of information about melody. Our results show that the errors made by pcd-based approach XX and phase based approach XXX  are complementary. Thus, they can potentially be combined to improve performance. In addition, An hierarchical model that combine these approaches based on the available information in the audio recording can be a promising future direction. ??

In addition to improve the approaches proposed in the our work, the output of our approaches can also facilitate novel reserach problems that have not been explored. In particular it can enable pattern-based corpora level charactterization of artists, compositions and ragas. Through the interlinked audio recordings in terms of the common melodic patterns one can define novel similarity measures between these entities. Also a quantitative study of similarity between ragas can be addressed by through an analysis of interlinked melodic patterns. 

All the different melodic elements studied in our work can be combined within a ontology framework to bulid knowledge bases, which can then enable musicologically relevant analysis??? Ask Gopala what can we write here



New analyses
0) Characterization based on melodic features
1) music similarity across recordings
2) Corpora level characterization 
3) Evolution of a music piece, discovery of melodic structures!!
4) All these melodic elements combined in music ontology and knowledge databases


%4) Pattern discovery - improving quality of the output patterns
%
%Boundaries of the pattern, extend ---however defining it formally is a complex task, since its always sung in a particular context, how to differentiate the context from the patter?
%Boundaries will improve similarity, and improve the quality
%Improving similarity -> improve this...
%trying other community detection methods
